{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CV_project_upd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XfgyXB0ehjV",
        "colab_type": "code",
        "outputId": "863b7fa9-cf99-4b12-9bd0-5ac65e1361f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i1t3eZaIPMPp",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import namedtuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "from torchvision import transforms, models\n",
        "import torchvision.transforms as T\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from shutil import copyfile, copy\n",
        "from IPython.display import clear_output\n",
        "\n",
        "os.makedirs(\"models\", exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISPCy1KpPfNS",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjXvmRMWoecU",
        "colab_type": "text"
      },
      "source": [
        "#### Download required files from my drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oOH5PgAmn1D",
        "colab_type": "code",
        "outputId": "426b8247-cdce-409f-80df-9e69e164aca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        print('\\nDownloading file...')\n",
        "        for chunk in tqdm(response.iter_content(CHUNK_SIZE), unit=\"KB\", leave=True):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "        print('File was successfully downloaded!')\n",
        "\n",
        "directory = 'models'\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "file_id = '1w9r1NoYnn7tql1VYG3qDUzkbIks24RBQ'\n",
        "destination = f'{directory}/decoder.pth'\n",
        "download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "file_id = '1X7x314BlP4XwH76TV50hRjv0HyM9Xhhm'\n",
        "destination = f'{directory}/vgg_relu4_1.pth'\n",
        "download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "file_id = '1_NjdWZIv63Yb9uMn3XkZjCQP3Z5HjZtC'\n",
        "destination = 'fruit_data.zip'\n",
        "download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "file_id = '1jAFyliSAJuSvWIcG12GRjY3zUaTuDK5z'\n",
        "destination = 'fruit_classifier.pth'\n",
        "download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "file_id = '1bXB5cTFrmG96t6AAIGAQkwUGzVkjLYSy'\n",
        "destination = 'id2class.pkl'\n",
        "download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "file_id = '1Z_hsaSpXGJoHoA21BMgC6ci6GrunR09s'\n",
        "destination = 'tests.zip'\n",
        "download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0KB [00:00, ?KB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading file...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "428KB [00:00, 1437.62KB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "File was successfully downloaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0KB [00:00, ?KB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading file...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "429KB [00:00, 1202.15KB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "File was successfully downloaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0KB [00:00, ?KB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading file...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "447KB [00:00, 921.95KB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "File was successfully downloaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "51KB [00:00, 3641.45KB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading file...\n",
            "File was successfully downloaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1KB [00:00, 2050.00KB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading file...\n",
            "File was successfully downloaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "11KB [00:00, 1525.50KB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading file...\n",
            "File was successfully downloaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLEEi5P7qUd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip fruit_data.zip \n",
        "!unzip tests.zip\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Coja7NQcsef0",
        "colab_type": "code",
        "outputId": "fd603360-ad7e-4047-b795-3972d750e168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.makedirs('content', exist_ok=True)\n",
        "os.makedirs('style', exist_ok=True)\n",
        "\n",
        "for subdir in os.listdir('fruit_data'):\n",
        "    for file in os.listdir('fruit_data/' + subdir):\n",
        "        copyfile(f'fruit_data/{subdir}/{file}', f'content/{subdir}_{file}')\n",
        "\n",
        "os.system('cp -r content/. style/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcysi1fEPbbv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Implementation code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMTOCSDOS8hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sampler(data.sampler.Sampler):\n",
        "    def __init__(self, data_source):\n",
        "        self.num_samples = len(data_source)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.__sampler(self.num_samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return 2 ** 31\n",
        "    \n",
        "    def __sampler(self, n):\n",
        "        i = n - 1\n",
        "        order = np.random.permutation(n)\n",
        "        while True:\n",
        "            yield order[i]\n",
        "            i += 1\n",
        "            if i >= n:\n",
        "                np.random.seed()\n",
        "                order = np.random.permutation(n)\n",
        "                i = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg1NZWllTLVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataset(data.Dataset):\n",
        "    def __init__(self, root, transform):\n",
        "        super(ImageDataset, self).__init__()\n",
        "        self.root = root\n",
        "        self.paths = list(Path(self.root).glob('*'))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.paths[index]\n",
        "        img = Image.open(str(path)).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def name(self):\n",
        "        return 'ImageDataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69x7FYGZRtUW",
        "colab_type": "text"
      },
      "source": [
        "#### Model structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkIXNz7CQpUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decoder structure\n",
        "decoder = nn.Sequential(\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 128, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 128, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 64, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 64, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 3, (3, 3)),\n",
        ")\n",
        "\n",
        "vgg = torch.load('models/vgg_relu4_1.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsafYqpYQjAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mean_std(features):\n",
        "    \"\"\"Compute mean and std for a given features data\"\"\"\n",
        "    dims = [*features.size()[:2], 1, 1]\n",
        "    features_var = features.view(*dims[:2], -1).var(dim=2) + 1e-5\n",
        "    features_std = torch.sqrt(features_var).view(dims)\n",
        "    features_mean = torch.mean(features.view(*dims[:2], -1), 2).view(dims)\n",
        "    return features_mean, features_std\n",
        "\n",
        "\n",
        "def adaIN(content_f, style_f):\n",
        "    \"\"\"Implementation of adapive instance normalization from the paper\"\"\"\n",
        "    dims = content_f.size()\n",
        "    s_mean, s_std = get_mean_std(style_f)\n",
        "    c_mean, c_std = get_mean_std(content_f)\n",
        "\n",
        "    normalized_features = (content_f - c_mean.expand(dims)) / c_std.expand(dims)\n",
        "    return normalized_features * s_std.expand(dims) + s_mean.expand(dims)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuQaEaopRxXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StyleModel(nn.Module):\n",
        "    def __init__(self, vgg, decoder):\n",
        "        super(StyleModel, self).__init__()\n",
        "        self.decoder = decoder\n",
        "        vgg_layers = list(vgg.children())\n",
        "        self.relu1_1 = nn.Sequential(*vgg_layers[:4])\n",
        "        self.relu2_1 = nn.Sequential(*vgg_layers[4:11])\n",
        "        self.relu3_1 = nn.Sequential(*vgg_layers[11:18])\n",
        "        self.relu4_1 = nn.Sequential(*vgg_layers[18:31])\n",
        "\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "        # do not change weights for pretrained vgg\n",
        "        for name in ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1']:\n",
        "            for param in getattr(self, name).parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def encode(self, source, intermediate=False):\n",
        "        \"\"\"Extract relu1_1, relu2_1, relu3_1, relu4_1 from source image\n",
        "        if intermediate is True, otherwise return result of relu4_1\"\"\"\n",
        "        r1 = self.relu1_1(source)\n",
        "        r2 = self.relu2_1(r1)\n",
        "        r3 = self.relu3_1(r2)\n",
        "        r4 = self.relu4_1(r3)\n",
        "        return [r1, r2, r3, r4] if intermediate else r4\n",
        "    \n",
        "    def compute_style_loss(self, source, target):\n",
        "        \"\"\"Compute style loss between source and target\"\"\"\n",
        "        source_mean, source_std = get_mean_std(source)\n",
        "        target_mean, target_std = get_mean_std(target)\n",
        "        mean_loss = self.mse_loss(source_mean, target_mean)\n",
        "        std_loss = self.mse_loss(source_std, target_std)\n",
        "        return mean_loss + std_loss\n",
        "\n",
        "    def forward(self, content, style):\n",
        "        # get features for style and content\n",
        "        style_features = self.encode(style, intermediate=True)\n",
        "        content_features = self.encode(content)\n",
        "\n",
        "        # apply adaptive instance normalization\n",
        "        t = adaIN(content_features, style_features[-1])\n",
        "\n",
        "        g_t = self.decoder(t)\n",
        "        g_t_features = self.encode(g_t, intermediate=True)\n",
        "\n",
        "        # compute content loss with last feature representation\n",
        "        loss_content = self.mse_loss(g_t_features[-1], t)\n",
        "        \n",
        "        # compute style loss across all feature representations\n",
        "        loss_style = 0\n",
        "        for i in range(4):\n",
        "            loss_style += self.compute_style_loss(\n",
        "                g_t_features[i], style_features[i]\n",
        "            )\n",
        "        \n",
        "        return loss_content, loss_style"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XAh9jA3UZFR",
        "colab_type": "text"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGqvmkioSoDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjust_learning_rate(lr, lr_decay, optimizer, iteration_count):\n",
        "    \"\"\"Adjust learning rate for the current iteration\"\"\"\n",
        "    lr = lr / (1.0 + lr_decay * iteration_count)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def train_model(vgg, decoder, content_path, style_path, lr,\n",
        "                max_iter=10000, style_weight=10, save_iter=1000):\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    # Make directory to save models\n",
        "    save_dir = \"/content/drive/My Drive/CV_project/model_versions\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    model = StyleModel(vgg, decoder)\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "         transforms.Resize(size=(512, 512)),\n",
        "         transforms.RandomCrop(256),\n",
        "         transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    content_dataset = ImageDataset(content_path, transform)\n",
        "    style_dataset = ImageDataset(style_path, transform)\n",
        "\n",
        "    content_iter = iter(data.DataLoader(content_dataset, batch_size=8,\n",
        "                                        sampler=Sampler(content_dataset),\n",
        "                                        num_workers=16))\n",
        "\n",
        "    style_iter = iter(data.DataLoader(style_dataset, batch_size=8,\n",
        "                                      sampler=Sampler(style_dataset),\n",
        "                                      num_workers=16))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for i in range(1, max_iter + 1):\n",
        "        # adjust learning rate with each iteration\n",
        "        adjust_learning_rate(lr, 5e-5, optimizer, iteration_count=i)\n",
        "\n",
        "        content_images = next(content_iter).to(device)\n",
        "        style_images = next(style_iter).to(device)\n",
        "\n",
        "        # compute losses\n",
        "        loss_c, loss_s = model(content_images, style_images)\n",
        "        loss = loss_c + style_weight * loss_s\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f'\\rIteration [{i}/{max_iter}]', end='')\n",
        "\n",
        "        # Save model with specific interval\n",
        "        if (i + 1) % save_iter == 0 or (i + 1) == max_iter:\n",
        "            state_dict = decoder.state_dict()\n",
        "            for key in state_dict.keys():\n",
        "                state_dict[key] = state_dict[key].to(torch.device('cpu'))\n",
        "            torch.save(state_dict, f'{save_dir}/decoder_iter_{i + 1}.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wfC2r1t8k4M",
        "colab_type": "code",
        "outputId": "09688b3c-2525-4ba5-b7f2-861c00a3a473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_model(vgg, decoder, './content', './style', lr=1e-4,\n",
        "            max_iter=10000, style_weight=12, save_iter=2500)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration [10000/10000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNTK3ZcDUayx",
        "colab_type": "text"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkBjEKS3UcQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(vgg, decoder, decoder_path, test_paths, show_result=True):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    output_dir = Path(test_paths.output_path)\n",
        "    output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    content_dir = Path(test_paths.content_path)\n",
        "    content_paths = [f for f in content_dir.glob('*')]\n",
        "\n",
        "    style_path = Path(test_paths.style)\n",
        "\n",
        "    decoder.eval()\n",
        "    vgg.eval()\n",
        "\n",
        "    decoder.load_state_dict(torch.load(decoder_path))\n",
        "\n",
        "    vgg.to(device)\n",
        "    decoder.to(device)\n",
        "\n",
        "    transform = transforms.Compose([transforms.Resize(100),\n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "    for content_path in content_paths:\n",
        "        content = Image.open(str(content_path))\n",
        "        if show_result:\n",
        "            print('Content:')\n",
        "            display(content)\n",
        "        content = transform(content)\n",
        "        \n",
        "        style = Image.open(str(style_path))\n",
        "        if show_result:\n",
        "            print('Style:')\n",
        "            display(style)\n",
        "        style = transform(style)\n",
        "\n",
        "        style = style.to(device).unsqueeze(0)\n",
        "        content = content.to(device).unsqueeze(0)\n",
        "\n",
        "        # transfer style to content image\n",
        "        with torch.no_grad():\n",
        "            content_feat = vgg(content)\n",
        "            fs = adaIN(content_feat, vgg(style))\n",
        "            output = decoder(fs)\n",
        "\n",
        "        output = output.cpu()\n",
        "        output_name = output_dir / '{:s}_style_{:s}.jpg'.format(\n",
        "            content_path.stem, style_path.stem)\n",
        "        \n",
        "        save_image(output, str(output_name))\n",
        "        if show_result:\n",
        "            print('Result:')\n",
        "            display(Image.open(str(output_name))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsxpfSbvTqct",
        "colab_type": "text"
      },
      "source": [
        "#### Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W35NxaEMKnDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FruitClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, classes, id2class):\n",
        "        super(FruitClassifier, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=5, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 64, kernel_size=7, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3),\n",
        "            nn.Conv2d(64, 64, kernel_size=7),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(5),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, classes)\n",
        "        )\n",
        "        self.id2class = id2class\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def load_weights(self, path):\n",
        "        self.model.load_state_dict(torch.load(path))\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.id2class[self.model(x).max(1)[1].cpu().item()]\n",
        "\n",
        "\n",
        "def load_image(filename, device='cpu'):\n",
        "    transform = T.Compose([T.ToTensor(),\n",
        "                           T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "    img = Image.open(filename)\n",
        "    img_t = transform(img)\n",
        "    return img_t.unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "with open('id2class.pkl', 'rb') as fd:\n",
        "    id2class = pickle.load(fd)\n",
        "\n",
        "clf = FruitClassifier(5, id2class)\n",
        "clf.load_weights('fruit_classifier.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD06LLtnJpY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TestPaths = namedtuple('TestPaths', \n",
        "                       field_names=['content_path', 'style', 'output_path'])\n",
        "\n",
        "def generate_test_results(decoder_path):\n",
        "    os.system('rm -rd test_results/')\n",
        "    fruit_dirs = os.listdir('tests/')\n",
        "    for style_fruit_dir in fruit_dirs:\n",
        "        style = sorted(os.listdir('tests/' + style_fruit_dir))[0]\n",
        "        style_im = 'tests/' + style_fruit_dir + '/' + style\n",
        "        for content_fruit_dir in fruit_dirs:\n",
        "            if (style_fruit_dir != content_fruit_dir):\n",
        "                content_path = 'tests/' + content_fruit_dir\n",
        "                output_path = 'test_results/' + content_fruit_dir + \\\n",
        "                              '_2_' + style_fruit_dir\n",
        "                \n",
        "                paths = TestPaths(content_path, style_im, output_path)\n",
        "                \n",
        "                test_model(vgg, decoder, decoder_path, paths, show_result=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D5EwweiOlyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_test_results(clf, path='test_results'):\n",
        "    total_checks = 0\n",
        "    style_transfer_score = 0\n",
        "    tricked_cnt = {'Apple': 0, 'Banana': 0, 'Cocos': 0, 'Lemon': 0, 'Orange': 0}\n",
        "    for result_dir in os.listdir(path):\n",
        "        _, style = result_dir.split('_2_')\n",
        "        for result in os.listdir(path + '/' + result_dir):\n",
        "            clf_class = clf.predict(load_image(path + '/' + result_dir + '/' + result))\n",
        "            if style == clf_class:\n",
        "                style_transfer_score += 1\n",
        "                tricked_cnt[style] += 1\n",
        "            total_checks += 1\n",
        "    \n",
        "    accuracy = float(style_transfer_score) / float(total_checks)\n",
        "    tricked_acc = dict((k, v / 60) for k, v in tricked_cnt.items())\n",
        "    return accuracy, tricked_acc, tricked_cnt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiPQFuRY75nU",
        "colab_type": "code",
        "outputId": "9c6e460b-a529-44a8-9fd6-caf32c319678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "decoder_path = \"models/decoder.pth\"\n",
        "\n",
        "print('Generating test results...', end='')\n",
        "generate_test_results(decoder_path)\n",
        "print(' -> Done!')\n",
        "print('Evaluating test results...', end='')\n",
        "\n",
        "res = eval_test_results(clf)\n",
        "print(' -> Done!')\n",
        "print('Total accuracy:', res[0])\n",
        "print('Per fruit accuracy:', res[1])\n",
        "print('Classified counts:', res[2])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating test results... -> Done!\n",
            "Evaluating test results... -> Done!\n",
            "Total accuracy: 0.46\n",
            "Per fruit accuracy: {'Apple': 0.4666666666666667, 'Banana': 0.2, 'Cocos': 0.016666666666666666, 'Lemon': 0.7333333333333333, 'Orange': 0.8833333333333333}\n",
            "Classified counts: {'Apple': 28, 'Banana': 12, 'Cocos': 1, 'Lemon': 44, 'Orange': 53}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}